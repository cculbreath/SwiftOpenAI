# SwiftOpenAI - Streaming TTS Support

## Overview

This fork of SwiftOpenAI adds support for streaming Text-to-Speech (TTS), allowing real-time audio playback as chunks are generated by OpenAI's API.

## Features

- ✅ Streaming TTS support via `createStreamingSpeech()`  
- ✅ Chunk-based audio streaming with `AudioSpeechChunkObject`
- ✅ Native Swift async/await implementation
- ✅ Built-in error handling and completion detection
- ✅ Configurable chunk sizes for optimal performance
- ✅ Full compatibility with existing SwiftOpenAI features

## Usage

### Basic Streaming TTS

```swift
import SwiftOpenAI

let service = OpenAIServiceFactory.service(apiKey: "your-api-key")

let parameters = AudioSpeechParameters(
    model: .tts1,
    input: "Hello, this is streaming text-to-speech!",
    voice: .alloy,
    stream: true // Enable streaming
)

let stream = try await service.createStreamingSpeech(parameters: parameters)

for try await chunk in stream {
    if chunk.isLastChunk {
        print("Streaming completed")
        break
    } else {
        // Process audio chunk
        audioPlayer.append(chunk.chunk)
    }
}
```

### Integration with Audio Players

The streaming chunks can be easily integrated with audio players:

```swift
class StreamingAudioPlayer {
    private let audioPlayer = ChunkedAudioPlayer()
    
    func playStreamingTTS(text: String, voice: String) async {
        let parameters = AudioSpeechParameters(
            model: .tts1,
            input: text,
            voice: mapVoice(voice),
            stream: true
        )
        
        let stream = try await service.createStreamingSpeech(parameters: parameters)
        
        for try await chunk in stream {
            if chunk.isLastChunk {
                audioPlayer.finish()
                break
            } else {
                audioPlayer.appendChunk(chunk.chunk)
            }
        }
    }
}
```

## API Reference

### AudioSpeechParameters

Extended to include streaming support:

```swift
public struct AudioSpeechParameters: Encodable {
    public init(
        model: TTSModel,
        input: String,
        voice: Voice,
        responseFormat: ResponseFormat? = nil,
        speed: Double? = nil,
        stream: Bool? = nil  // NEW: Enable streaming
    )
}
```

### AudioSpeechChunkObject

Represents a single chunk of streaming audio:

```swift
public struct AudioSpeechChunkObject {
    /// The audio chunk data
    public let chunk: Data
    
    /// Indicates if this is the final chunk
    public let isLastChunk: Bool
    
    /// Optional metadata about the chunk
    public let chunkIndex: Int?
}
```

### OpenAIService Protocol

New streaming method:

```swift
func createStreamingSpeech(
    parameters: AudioSpeechParameters
) async throws -> AsyncThrowingStream<AudioSpeechChunkObject, Error>
```

## Implementation Details

- **Chunk Size**: Default 4096 bytes for optimal streaming performance
- **Error Handling**: Full error propagation with detailed error messages
- **Memory Efficiency**: Processes chunks as they arrive, minimal memory footprint
- **Completion Detection**: Automatic detection of stream completion
- **Cancellation Support**: Built-in task cancellation when stream terminates

## Performance Considerations

- Streaming reduces initial latency compared to full audio generation
- Optimal for long-form text content
- Chunk size can be adjusted based on network conditions
- Memory usage scales with chunk processing speed

## Installation

This is a fork of the original SwiftOpenAI library. To use in your project:

### Swift Package Manager

Add to your `Package.swift`:

```swift
dependencies: [
    .package(url: "https://github.com/[your-username]/SwiftOpenAI.git", branch: "feature/streaming-tts")
]
```

Or add via Xcode's package manager using the repository URL.

## Migration from MacPaw/OpenAI

If migrating from MacPaw's OpenAI library:

### Before (MacPaw)
```swift
client.audioCreateSpeechStream(query: query) { result in
    // Handle chunk
} completion: { error in
    // Handle completion
}
```

### After (SwiftOpenAI)
```swift
let stream = try await service.createStreamingSpeech(parameters: parameters)
for try await chunk in stream {
    if chunk.isLastChunk {
        // Handle completion
    } else {
        // Handle chunk
    }
}
```

## Testing

Run the included tests:

```bash
swift test
```

The test suite includes:
- Parameter validation
- Chunk object creation
- Method signature verification
- Error handling scenarios

## Contributing

This feature adds streaming TTS support to SwiftOpenAI. Contributions are welcome:

1. Fork the repository
2. Create a feature branch
3. Add comprehensive tests
4. Submit a pull request

## License

This fork maintains the same license as the original SwiftOpenAI project.

## Credits

- Original SwiftOpenAI by James Rochabrun
- Streaming TTS implementation by SwiftOpenAI Community
- Inspired by OpenAI's streaming API capabilities
